{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsT5xXIKakx5gt1FiE+WFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandhini1008/classification/blob/main/predicting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V6cDl6-wgG_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "a50bf1eb-08a5-49cf-d7e6-394a3c9c2351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 USAGE EXAMPLES:\n",
            "==================================================\n",
            "\n",
            "# Initialize predictor with your .pkl file:\n",
            "predictor = DeepfakePredictor('your_model.pkl')\n",
            "\n",
            "# Predict single image:\n",
            "result = predictor.predict_image('path/to/image.jpg')\n",
            "\n",
            "# Test different preprocessing methods:\n",
            "test_different_preprocessing(predictor, 'path/to/image.jpg')\n",
            "\n",
            "# Batch prediction:\n",
            "results = predictor.predict_batch(['image1.jpg', 'image2.jpg'])\n",
            "\n",
            "# Full pipeline:\n",
            "main_prediction_pipeline('your_model.pkl', ['test1.jpg', 'test2.jpg'])\n",
            "\n",
            "==================================================\n",
            "🚀 DEEPFAKE PREDICTION PIPELINE\n",
            "============================================================\n",
            "🔄 Loading model from /content/three_class_model_20250905_110508.pkl\n",
            "❌ Error loading model: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n",
            "💡 Trying alternative loading methods...\n",
            "❌ All loading methods failed: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n",
            "💡 Please check your model file format\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2670323187.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# Load with explicit CPU mapping using lambda function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             self.model = torch.load(buffer, \n\u001b[0m\u001b[1;32m    180\u001b[0m                                    \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1746\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m                 \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2670323187.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/three_class_model_20250905_110508.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/sample_data/chk.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/sample_data/chk2.jpg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m \u001b[0mmain_prediction_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2670323187.py\u001b[0m in \u001b[0;36mmain_prediction_pipeline\u001b[0;34m(model_path, test_images)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Initialize predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepfakePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;31m# Test single images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2670323187.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, device)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2670323187.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 loaded_obj = torch.load(buffer, \n\u001b[0m\u001b[1;32m    207\u001b[0m                                        \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                        weights_only=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1810\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m                 \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \"\"\"\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "# ===============================================================================\n",
        "# IMPROVED DEEPFAKE PREDICTOR WITH CONSISTENT PROCESSING\n",
        "# ===============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import io\n",
        "import os\n",
        "import warnings\n",
        "import joblib\n",
        "import dill\n",
        "import hashlib\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ===============================================================================\n",
        "# EXACT MODEL ARCHITECTURE (Must match training)\n",
        "# ===============================================================================\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    \"\"\"CNN classifier - MUST exactly match your trained model architecture\"\"\"\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(SimpleClassifier, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Conv Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Conv Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Conv Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# ===============================================================================\n",
        "# CONSISTENT IMAGE PREPROCESSOR\n",
        "# ===============================================================================\n",
        "\n",
        "class ConsistentImagePreprocessor:\n",
        "    \"\"\"\n",
        "    Ensures consistent image preprocessing that matches training pipeline\n",
        "    \"\"\"\n",
        "    def __init__(self, target_size=(224, 224), normalization='imagenet'):\n",
        "        self.target_size = target_size\n",
        "        self.normalization = normalization\n",
        "\n",
        "        # Define exact preprocessing that should match training\n",
        "        if normalization == 'imagenet':\n",
        "            # Standard ImageNet normalization\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                   std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        elif normalization == 'custom':\n",
        "            # Custom normalization (modify based on your training)\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                   std=[0.5, 0.5, 0.5])\n",
        "            ])\n",
        "        else:\n",
        "            # No normalization - just resize and convert to tensor\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(target_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Preprocess image consistently\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load image\n",
        "            if isinstance(image_path, str):\n",
        "                image = Image.open(image_path).convert('RGB')\n",
        "                print(f\"Loaded image: {os.path.basename(image_path)} - Size: {image.size}\")\n",
        "            else:\n",
        "                image = image_path\n",
        "                print(f\"Using provided image - Size: {image.size}\")\n",
        "\n",
        "            # Apply preprocessing\n",
        "            tensor = self.transform(image)\n",
        "\n",
        "            # Log preprocessing details\n",
        "            print(f\"Preprocessed tensor shape: {tensor.shape}\")\n",
        "            print(f\"Tensor range: [{tensor.min():.3f}, {tensor.max():.3f}]\")\n",
        "            print(f\"Tensor mean: {tensor.mean():.3f}, std: {tensor.std():.3f}\")\n",
        "\n",
        "            return tensor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing image: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_tensor_sample(self, image_path, label=None):\n",
        "        \"\"\"\n",
        "        Create tensor sample in the exact format used during training\n",
        "        \"\"\"\n",
        "        tensor = self.preprocess_image(image_path)\n",
        "        if tensor is None:\n",
        "            return None\n",
        "\n",
        "        sample = {\n",
        "            'pixel_values': tensor,\n",
        "        }\n",
        "\n",
        "        if label is not None:\n",
        "            sample['labels'] = label\n",
        "\n",
        "        return sample\n",
        "\n",
        "# ===============================================================================\n",
        "# ROBUST MODEL LOADER\n",
        "# ===============================================================================\n",
        "\n",
        "class RobustModelLoader:\n",
        "    \"\"\"\n",
        "    Handles different model file formats and corruption\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model_safely(model_path, model_class=SimpleClassifier, num_classes=3):\n",
        "        \"\"\"\n",
        "        Safely load model with multiple fallback methods\n",
        "        \"\"\"\n",
        "        print(f\"Attempting to load model from: {model_path}\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Model file not found: {model_path}\")\n",
        "            return None, \"file_not_found\"\n",
        "\n",
        "        # Get file hash for consistency check\n",
        "        file_hash = RobustModelLoader._get_file_hash(model_path)\n",
        "        print(f\"Model file hash: {file_hash}\")\n",
        "\n",
        "        # Try different loading methods\n",
        "        loading_methods = [\n",
        "            (\"PyTorch state_dict\", RobustModelLoader._load_pytorch_state_dict),\n",
        "            (\"PyTorch model object\", RobustModelLoader._load_pytorch_model),\n",
        "            (\"Pickle state_dict\", RobustModelLoader._load_pickle_state_dict),\n",
        "            (\"Pickle model object\", RobustModelLoader._load_pickle_model),\n",
        "            (\"Joblib\", RobustModelLoader._load_joblib),\n",
        "            (\"Manual reconstruction\", RobustModelLoader._manual_load)\n",
        "        ]\n",
        "\n",
        "        for method_name, method_func in loading_methods:\n",
        "            print(f\"Trying method: {method_name}\")\n",
        "            try:\n",
        "                model = method_func(model_path, model_class, num_classes)\n",
        "                if model is not None:\n",
        "                    print(f\"Successfully loaded model using: {method_name}\")\n",
        "                    return model, method_name\n",
        "            except Exception as e:\n",
        "                print(f\"Failed with {method_name}: {str(e)[:100]}\")\n",
        "\n",
        "        print(\"All loading methods failed\")\n",
        "        return None, \"failed\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_file_hash(file_path):\n",
        "        \"\"\"Get file hash for consistency checking\"\"\"\n",
        "        with open(file_path, 'rb') as f:\n",
        "            content = f.read()\n",
        "        return hashlib.md5(content).hexdigest()[:8]\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_pytorch_state_dict(model_path, model_class, num_classes):\n",
        "        \"\"\"Load as PyTorch state dict\"\"\"\n",
        "        state_dict = torch.load(model_path, map_location='cpu')\n",
        "        if isinstance(state_dict, dict):\n",
        "            model = model_class(num_classes=num_classes)\n",
        "            model.load_state_dict(state_dict)\n",
        "            return model\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_pytorch_model(model_path, model_class, num_classes):\n",
        "        \"\"\"Load as complete PyTorch model\"\"\"\n",
        "        model = torch.load(model_path, map_location='cpu')\n",
        "        if hasattr(model, 'forward'):\n",
        "            return model\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_pickle_state_dict(model_path, model_class, num_classes):\n",
        "        \"\"\"Load as pickled state dict\"\"\"\n",
        "        with open(model_path, 'rb') as f:\n",
        "            state_dict = pickle.load(f)\n",
        "        if isinstance(state_dict, dict):\n",
        "            model = model_class(num_classes=num_classes)\n",
        "            model.load_state_dict(state_dict)\n",
        "            return model\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_pickle_model(model_path, model_class, num_classes):\n",
        "        \"\"\"Load as pickled model\"\"\"\n",
        "        with open(model_path, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "        if hasattr(model, 'forward'):\n",
        "            return model\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_joblib(model_path, model_class, num_classes):\n",
        "        \"\"\"Load using joblib\"\"\"\n",
        "        loaded = joblib.load(model_path)\n",
        "        if hasattr(loaded, 'forward'):\n",
        "            return loaded\n",
        "        elif isinstance(loaded, dict):\n",
        "            model = model_class(num_classes=num_classes)\n",
        "            model.load_state_dict(loaded)\n",
        "            return model\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _manual_load(model_path, model_class, num_classes):\n",
        "        \"\"\"Manual loading with error handling\"\"\"\n",
        "        # Try to read file as binary and extract useful parts\n",
        "        with open(model_path, 'rb') as f:\n",
        "            data = f.read()\n",
        "\n",
        "        # Try different byte offsets in case of header corruption\n",
        "        for offset in [0, 8, 16, 32, 64]:\n",
        "            try:\n",
        "                buffer = io.BytesIO(data[offset:])\n",
        "                loaded = pickle.load(buffer)\n",
        "                if isinstance(loaded, dict):\n",
        "                    model = model_class(num_classes=num_classes)\n",
        "                    model.load_state_dict(loaded)\n",
        "                    return model\n",
        "                elif hasattr(loaded, 'forward'):\n",
        "                    return loaded\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return None\n",
        "\n",
        "# ===============================================================================\n",
        "# CONSISTENT DEEPFAKE PREDICTOR\n",
        "# ===============================================================================\n",
        "\n",
        "class ConsistentDeepfakePredictor:\n",
        "    \"\"\"\n",
        "    Consistent predictor that ensures reproducible results\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path, preprocessing_config=None, device=None):\n",
        "        self.model_path = model_path\n",
        "        self.device = device or torch.device('cpu')\n",
        "        self.class_names = ['AI-generated', 'Deepfake', 'Real']\n",
        "\n",
        "        # Set up consistent preprocessing\n",
        "        if preprocessing_config is None:\n",
        "            preprocessing_config = {\n",
        "                'target_size': (224, 224),\n",
        "                'normalization': 'imagenet'  # Change this to match your training\n",
        "            }\n",
        "\n",
        "        self.preprocessor = ConsistentImagePreprocessor(**preprocessing_config)\n",
        "        self.model = None\n",
        "        self.loading_method = None\n",
        "        self.model_hash = None\n",
        "\n",
        "        # Load model\n",
        "        self._load_model()\n",
        "\n",
        "        # Set deterministic behavior\n",
        "        torch.manual_seed(42)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(42)\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load model with error handling\"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"CONSISTENT MODEL LOADING\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        self.model, self.loading_method = RobustModelLoader.load_model_safely(\n",
        "            self.model_path, SimpleClassifier, 3\n",
        "        )\n",
        "\n",
        "        if self.model is None:\n",
        "            print(\"WARNING: Could not load trained model. Creating untrained fallback.\")\n",
        "            print(\"This will give random predictions!\")\n",
        "            self.model = SimpleClassifier(num_classes=3)\n",
        "            self.loading_method = \"untrained_fallback\"\n",
        "\n",
        "        # Ensure model is in evaluation mode\n",
        "        self.model.eval()\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "        # Disable dropout for consistent results\n",
        "        for module in self.model.modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0.0\n",
        "\n",
        "        print(f\"Model loading status: {self.loading_method}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    def predict_image(self, image_path, show_details=True):\n",
        "        \"\"\"\n",
        "        Make consistent prediction on image\n",
        "        \"\"\"\n",
        "        if show_details:\n",
        "            print(f\"\\nPREDICTING: {os.path.basename(image_path)}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Model status: {self.loading_method}\")\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image not found: {image_path}\")\n",
        "            return None\n",
        "\n",
        "        # Preprocess image\n",
        "        tensor = self.preprocessor.preprocess_image(image_path)\n",
        "        if tensor is None:\n",
        "            return None\n",
        "\n",
        "        # Make prediction\n",
        "        batch_tensor = tensor.unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(batch_tensor)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence_scores = probabilities[0].cpu().numpy()\n",
        "\n",
        "        # Results\n",
        "        result = {\n",
        "            'predicted_class': predicted_class,\n",
        "            'predicted_label': self.class_names[predicted_class],\n",
        "            'confidence': confidence_scores[predicted_class],\n",
        "            'all_probabilities': confidence_scores,\n",
        "            'model_status': self.loading_method\n",
        "        }\n",
        "\n",
        "        if show_details:\n",
        "            print(f\"Prediction: {self.class_names[predicted_class]}\")\n",
        "            print(f\"Confidence: {confidence_scores[predicted_class]*100:.2f}%\")\n",
        "\n",
        "            if self.loading_method != \"untrained_fallback\":\n",
        "                print(\"\\nAll probabilities:\")\n",
        "                for i, (class_name, prob) in enumerate(zip(self.class_names, confidence_scores)):\n",
        "                    bar = \"█\" * int(prob * 20)\n",
        "                    print(f\"  {class_name:12}: {prob*100:6.2f}% |{bar}\")\n",
        "            else:\n",
        "                print(\"WARNING: Using untrained model - predictions are random!\")\n",
        "\n",
        "            # Show image with prediction\n",
        "            self._display_result(image_path, result)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _display_result(self, image_path, result):\n",
        "        \"\"\"Display image with prediction\"\"\"\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "\n",
        "            title = f\"Prediction: {result['predicted_label']} ({result['confidence']*100:.1f}%)\\n\"\n",
        "            title += f\"Status: {result['model_status']}\"\n",
        "\n",
        "            if result['model_status'] == \"untrained_fallback\":\n",
        "                title += \" (RANDOM PREDICTIONS)\"\n",
        "\n",
        "            plt.title(title, fontsize=12, pad=20)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Could not display image: {e}\")\n",
        "\n",
        "    def create_tensor_samples(self, image_paths, labels=None):\n",
        "        \"\"\"\n",
        "        Create consistent tensor samples for training/testing\n",
        "        \"\"\"\n",
        "        print(\"Creating consistent tensor samples...\")\n",
        "        tensor_samples = []\n",
        "\n",
        "        for i, image_path in enumerate(image_paths):\n",
        "            label = labels[i] if labels is not None else None\n",
        "            sample = self.preprocessor.create_tensor_sample(image_path, label)\n",
        "            if sample is not None:\n",
        "                tensor_samples.append(sample)\n",
        "                print(f\"Processed: {os.path.basename(image_path)}\")\n",
        "\n",
        "        print(f\"Created {len(tensor_samples)} tensor samples\")\n",
        "        return tensor_samples\n",
        "\n",
        "    def test_consistency(self, image_path, num_runs=5):\n",
        "        \"\"\"\n",
        "        Test prediction consistency across multiple runs\n",
        "        \"\"\"\n",
        "        print(f\"\\nTESTING CONSISTENCY: {os.path.basename(image_path)}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for run in range(num_runs):\n",
        "            print(f\"Run {run + 1}:\")\n",
        "            result = self.predict_image(image_path, show_details=False)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "                print(f\"  {result['predicted_label']} ({result['confidence']*100:.2f}%)\")\n",
        "\n",
        "        # Check consistency\n",
        "        if results:\n",
        "            predictions = [r['predicted_label'] for r in results]\n",
        "            confidences = [r['confidence'] for r in results]\n",
        "\n",
        "            unique_predictions = set(predictions)\n",
        "            consistent = len(unique_predictions) == 1\n",
        "\n",
        "            print(f\"\\nConsistency Analysis:\")\n",
        "            print(f\"  Unique predictions: {len(unique_predictions)}\")\n",
        "            print(f\"  Consistent: {'Yes' if consistent else 'No'}\")\n",
        "            print(f\"  Confidence std: {np.std(confidences):.4f}\")\n",
        "\n",
        "            if consistent:\n",
        "                print(f\"  Stable prediction: {predictions[0]}\")\n",
        "            else:\n",
        "                print(f\"  Prediction counts: {dict(zip(*np.unique(predictions, return_counts=True)))}\")\n",
        "\n",
        "# ===============================================================================\n",
        "# PTH FILE SPECIFIC HANDLER\n",
        "# ===============================================================================\n",
        "\n",
        "class PTHModelHandler:\n",
        "    \"\"\"\n",
        "    Specialized handler for PyTorch .pth files\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def inspect_pth_file(model_path):\n",
        "        \"\"\"\n",
        "        Inspect .pth file contents and structure\n",
        "        \"\"\"\n",
        "        print(f\"INSPECTING PTH FILE: {model_path}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            checkpoint = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "            print(f\"File type: {type(checkpoint)}\")\n",
        "\n",
        "            if isinstance(checkpoint, dict):\n",
        "                print(f\"Dictionary keys: {list(checkpoint.keys())}\")\n",
        "\n",
        "                # Check each key\n",
        "                for key, value in checkpoint.items():\n",
        "                    print(f\"  {key}: {type(value)}\")\n",
        "\n",
        "                    if isinstance(value, dict):\n",
        "                        print(f\"    -> Dict with {len(value)} items\")\n",
        "                        if len(value) < 20:  # Show keys if not too many\n",
        "                            print(f\"    -> Keys: {list(value.keys())[:10]}\")\n",
        "                    elif hasattr(value, 'shape'):\n",
        "                        print(f\"    -> Shape: {value.shape}\")\n",
        "                    elif isinstance(value, (int, float, str)):\n",
        "                        print(f\"    -> Value: {value}\")\n",
        "\n",
        "            elif hasattr(checkpoint, 'state_dict'):\n",
        "                print(\"Complete model object detected\")\n",
        "                state_dict = checkpoint.state_dict()\n",
        "                print(f\"State dict keys: {len(state_dict)} parameters\")\n",
        "\n",
        "            return checkpoint\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error inspecting file: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def load_pth_model(model_path, model_class, num_classes=3):\n",
        "        \"\"\"\n",
        "        Load model from .pth file with comprehensive handling\n",
        "        \"\"\"\n",
        "        print(f\"LOADING PTH MODEL: {model_path}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        try:\n",
        "            checkpoint = torch.load(model_path, map_location='cpu')\n",
        "            print(f\"Loaded checkpoint type: {type(checkpoint)}\")\n",
        "\n",
        "            # Method 1: Direct model object\n",
        "            if hasattr(checkpoint, 'forward') and hasattr(checkpoint, 'state_dict'):\n",
        "                print(\"Method: Direct model object\")\n",
        "                return checkpoint.eval()\n",
        "\n",
        "            # Method 2: Dictionary with known keys\n",
        "            elif isinstance(checkpoint, dict):\n",
        "                # Try different common keys\n",
        "                state_dict_keys = ['state_dict', 'model_state_dict', 'model', 'net', 'network']\n",
        "\n",
        "                for key in state_dict_keys:\n",
        "                    if key in checkpoint:\n",
        "                        print(f\"Method: State dict from key '{key}'\")\n",
        "                        state_dict = checkpoint[key]\n",
        "\n",
        "                        if isinstance(state_dict, dict):\n",
        "                            model = model_class(num_classes=num_classes)\n",
        "                            model.load_state_dict(state_dict)\n",
        "                            return model.eval()\n",
        "\n",
        "                # Try treating the whole dict as state_dict\n",
        "                print(\"Method: Direct state dict\")\n",
        "                try:\n",
        "                    model = model_class(num_classes=num_classes)\n",
        "                    model.load_state_dict(checkpoint)\n",
        "                    return model.eval()\n",
        "                except Exception as e:\n",
        "                    print(f\"Direct state dict failed: {e}\")\n",
        "\n",
        "            # Method 3: If it's already a tensor dict, try direct loading\n",
        "            elif isinstance(checkpoint, dict) and all(isinstance(v, torch.Tensor) for v in checkpoint.values()):\n",
        "                print(\"Method: Pure tensor dictionary\")\n",
        "                model = model_class(num_classes=num_classes)\n",
        "                model.load_state_dict(checkpoint)\n",
        "                return model.eval()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"PTH loading error: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# ===============================================================================\n",
        "# ENHANCED PREDICTOR WITH PTH SUPPORT\n",
        "# ===============================================================================\n",
        "\n",
        "class EnhancedPTHPredictor(ConsistentDeepfakePredictor):\n",
        "    \"\"\"\n",
        "    Enhanced predictor with specialized .pth file support\n",
        "    \"\"\"\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Enhanced model loading with PTH file inspection\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ENHANCED PTH MODEL LOADING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # First inspect the file if it's a .pth file\n",
        "        if self.model_path.endswith('.pth'):\n",
        "            print(\"Detected .pth file - running inspection...\")\n",
        "            PTHModelHandler.inspect_pth_file(self.model_path)\n",
        "            print()\n",
        "\n",
        "            # Try PTH-specific loading first\n",
        "            self.model = PTHModelHandler.load_pth_model(\n",
        "                self.model_path, SimpleClassifier, 3\n",
        "            )\n",
        "\n",
        "            if self.model is not None:\n",
        "                self.loading_method = \"pth_specialized\"\n",
        "                print(\"Successfully loaded using PTH-specific handler\")\n",
        "            else:\n",
        "                print(\"PTH-specific loading failed, trying general methods...\")\n",
        "                # Fall back to general loading methods\n",
        "                super()._load_model()\n",
        "        else:\n",
        "            # Use general loading for non-.pth files\n",
        "            super()._load_model()\n",
        "\n",
        "        print(f\"Final model loading status: {self.loading_method}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "# ===============================================================================\n",
        "# USAGE EXAMPLES\n",
        "# ===============================================================================\n",
        "\n",
        "def run_pth_prediction_pipeline(model_path, test_images):\n",
        "    \"\"\"\n",
        "    Run prediction pipeline optimized for .pth files\n",
        "    \"\"\"\n",
        "    print(\"LAUNCHING PTH-OPTIMIZED DEEPFAKE PREDICTION PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize enhanced predictor\n",
        "    predictor = EnhancedPTHPredictor(\n",
        "        model_path=model_path,\n",
        "        preprocessing_config={\n",
        "            'target_size': (224, 224),\n",
        "            'normalization': 'imagenet'  # Adjust based on your training\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Test each image\n",
        "    for image_path in test_images:\n",
        "        if os.path.exists(image_path):\n",
        "            print(f\"\\nProcessing: {os.path.basename(image_path)}\")\n",
        "\n",
        "            # Single prediction\n",
        "            result = predictor.predict_image(image_path)\n",
        "\n",
        "            # Test consistency (important for verifying model loaded correctly)\n",
        "            predictor.test_consistency(image_path, num_runs=3)\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "        else:\n",
        "            print(f\"Image not found: {image_path}\")\n",
        "\n",
        "    return predictor\n",
        "\n",
        "def inspect_and_predict(model_path, image_path):\n",
        "    \"\"\"\n",
        "    Quick function to inspect model and make single prediction\n",
        "    \"\"\"\n",
        "    print(\"QUICK INSPECT AND PREDICT\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Inspect model file\n",
        "    if model_path.endswith('.pth'):\n",
        "        PTHModelHandler.inspect_pth_file(model_path)\n",
        "\n",
        "    # Make prediction\n",
        "    predictor = EnhancedPTHPredictor(model_path)\n",
        "    result = predictor.predict_image(image_path)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage for .pth files:\n",
        "if __name__ == \"__main__\":\n",
        "    # For .pth files\n",
        "    model_path = \"/content/sample_data/deepfake_classifier_simple.pth\"  # Change this to your .pth file path\n",
        "    test_images = [\"/content/sample_data/chk.jpg\", \"/content/sample_data/chk2.jpg\"]\n",
        "\n",
        "    # Run full pipeline\n",
        "    predictor = run_pth_prediction_pipeline(model_path, test_images)\n",
        "\n",
        "    # Or quick inspect and predict\n",
        "    # result = inspect_and_predict(model_path, test_images[0])\n",
        "\n",
        "    print(\"\\nPTH PREDICTION PIPELINE COMPLETED!\")\n",
        "\n",
        "    # For your specific files (update paths as needed):\n",
        "    \"\"\"\n",
        "    model_path = \"/content/sample_data/deepfake_classifier_simple.pth\"\n",
        "    test_images = [\"/content/sample_data/chk.jpg\", \"/content/sample_data/chk2.jpg\"]\n",
        "    predictor = run_pth_prediction_pipeline(model_path, test_images)\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzjlpQGMza0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}